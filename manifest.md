OPERATION UNDENIABLE: FINAL ROADMAP
7-Month Elite LLM Systems Engineer Campaign
Mission: Become a strategic asset for FAANG/AI companies (EU/UK offices)
Target Roles: SWE (ML Track) + ML Engineer + Applied Research Engineer
Commitment: 60-70 hours/week | Daily execution | Zero excuses
THE PRIME DIRECTIVE
Success Metrics
•
 Primary Goal: 2-5 offers from FAANG/Tier-1 AI companies with EU/UK
sponsorship
•
 Portfolio Goal: SubFifty production system with 100+ stars, 15-30 users, proven
<50ms latency
•
 Technical Goal: Top 1% LLM production systems expertise
•
 Network Goal: 20-30 warm connections at target companies
Operating Principles
•
 Daily Proof of Work: Git commit every single day (non-negotiable)
•
 Ship > Perfect: Working system beats perfect documentation
•
 Depth > Breadth: 120 problems deeply understood > 200 problems half-assed
•
 Build in Public: Share progress, engage communities, create visibility
MONTH 1: PYTHON MASTERY & FOUNDATION
Weeks 1-4 | Hours: 55-65/week
Objective
Master Python for production ML systems. Establish daily discipline and algorithmic
foundation.
Skills Focus
•
 Python OOP (classes, inheritance, design patterns)
•
 CLI development, file I/O, error handling
•
 REST APIs with FastAPI
•
 Git workflow mastery
•
 Testing fundamentals
Weekly Breakdown
Week 1: Python Fundamentals
•
 Learning (20h):
o
 Variables, loops, functions, data structures
o
 Resources: Corey Schafer YouTube (2x speed since you know
programming)
•
 Project (15h): OOP Calculator
o
 Classes, inheritance, factory pattern
o
 Comprehensive error handling
o
 Type hints throughout
•
 LeetCode (8h): 4 Easy problems (Arrays basics)
•
 Git: Daily commits, learn branching
Week 2: Python Intermediate
•
 Learning (15h):
o
 File I/O, JSON/CSV handling
o
 Regex, string processing
o
 Context managers
•
 Project (20h): CLI Text Analyzer
o
 File reading, word frequency, statistics
o
 Command-line interface (argparse)
o
 Export to CSV/JSON
•
 LeetCode (8h): 4 Easy (Strings, Hash Tables)
Week 3: APIs & Testing
•
 Learning (15h):
o
 FastAPI fundamentals
o
 REST principles
o
 pytest basics
•
 Project (20h): TODO API or URL Shortener
o
 CRUD operations
o
 SQLite integration
o
 API documentation (Swagger)
o
 Basic tests
•
 LeetCode (8h): 4 Easy (Two Pointers)
Week 4: Deployment & Polish
•
 Project (25h):
o
 Deploy API to Render/Railway
o
 Add rate limiting and validation
o
 Polish all 3 projects (README, docs, CI/CD)
•
 LeetCode (10h): 5 Easy (review patterns)
•
 Networking: Join r/LocalLLaMA, vLLM Discord (lurk mode)
•
 Blog (5h): "Operation Undeniable: Month 1 Foundation Complete"
Deliverables
•
 ✅ 3 GitHub projects (Calculator, Text Analyzer, API)
•
 ✅ Live deployed API with public URL
•
 ✅ 17 LeetCode Easy solved (100% mastery)
•
 ✅ 28-day commit streak
•
 ✅ First blog post published
Success Metrics
•
 All projects work and are documented
•
 Can explain time/space complexity for LeetCode problems
•
 Comfortable with Python syntax and FastAPI
•
 GitHub looks professional
MONTH 2: DSA MASTERY (PEAK 1)
Weeks 5-8 | Hours: 60-70/week | PEAK MONTH
Objective
Build algorithmic fluency through pattern mastery. This is your LEETCODE MONTH.
Skills Focus
•
 Trees (BFS, DFS, all traversals)
•
 Graphs (DFS, BFS, topological sort)
•
 Stacks, queues, linked lists
•
 Binary search, sorting fundamentals
•
 Pattern recognition (NeetCode 150 approach)
Weekly Breakdown
Week 5: Trees Foundation
•
 DSA (30h):
o
 Study: Tree traversals (inorder, preorder, postorder, level-order)
o
 Practice: 10 problems (NeetCode Trees section)
o
 Focus: Recursion patterns, BFS vs DFS
•
 Learning (15h): freeCodeCamp DSA Course (Trees section)
•
 Project (10h): Implement tree visualizer (optional, educational)
•
 Mock Interview: 1 session on Pramp (coding only)
Week 6: Graphs & Advanced Trees
•
 DSA (30h):
o
 Study: Graph representations, DFS, BFS, connected components
o
 Practice: 10 problems (8 trees, 5 graphs)
o
 Focus: Adjacency lists, graph traversal patterns
•
 Learning (15h): NeetCode videos for patterns
•
 NumPy (8h): Start learning (arrays, reshaping, broadcasting)
Week 7: Stacks, Queues, Sorting
•
 DSA (30h):
o
 Study: Stack patterns (monotonic stacks), queue patterns
o
 Practice: 10 problems (stacks, queues, binary search)
o
 Focus: When to use each data structure
•
 ML Basics (10h): NumPy + scikit-learn intro
•
 Mock Interview: 1 session
Week 8: Review & Consolidation
•
 DSA (25h):
o
 Practice: 8 problems (weak areas + new mediums)
o
 Review: All patterns from Month 2
o
 Time yourself: 45 min max per problem
•
 Learning (15h): Start 3Blue1Brown Neural Networks series
•
 Networking (5h): Comment on 5-10 discussions in communities
•
 Blog (8h): "My NeetCode Journey: From Trees to Graphs"
•
 Mock Interview: 1 session
Deliverables
•
 ✅ 38 Medium problems solved (total: 55 problems)
•
 ✅ Can solve tree/graph problems independently
•
 ✅ DSA patterns documented in GitHub repo
•
 ✅ 3 mock interviews completed
•
 ✅ NumPy basics understood
•
 ✅ Blog post published
Success Metrics
•
 Trees and graphs feel natural
•
 Can explain approach before coding
•
 80%+ success rate on Medium problems
•
 Mock interview feedback shows improvement
MONTH 3: ML FOUNDATIONS & TRANSFORMERS
Weeks 9-12 | Hours: 55-65/week
Objective
Build deep ML intuition from first principles. Understand transformers completely.
Skills Focus
•
 Linear algebra & calculus intuition
•
 Linear/logistic regression from scratch
•
 Neural networks from scratch
•
 Backpropagation (manual derivation)
•
 Transformer architecture (attention mechanism)
Weekly Breakdown
Week 9: Math Foundations
•
 Math (20h):
o
 3Blue1Brown: "Essence of Linear Algebra" (complete series)
o
 Khan Academy: Calculus (derivatives, chain rule)
o
 Goal: Visual intuition, not proofs
•
 ML Theory (15h):
o
 Andrew Ng ML course: Week 1-2
o
 Understand: Cost functions, gradient descent
•
 Project (15h): Linear regression from scratch (NumPy only)
o
 Gradient descent implementation
o
 Vectorized operations
o
 Cost visualization
•
 LeetCode (8h): 4 Medium (Linked Lists)
•
 Blog planning: Outline "Understanding Transformers" article
Week 10: Neural Networks from Scratch
•
 ML Theory (20h):
o
 Andrew Ng: Week 3-4 (neural networks)
o
 3Blue1Brown: Neural Networks series
•
 Project (20h):
o
 Logistic regression (NumPy only)
o
 2-layer neural network (NumPy only)
o
 Forward pass + backpropagation by hand
o
 Activation functions (ReLU, Sigmoid)
•
 LeetCode (8h): 4 Medium (Stacks, DP intro)
•
 PyTorch (5h): Start official tutorials (tensors, autograd)
Week 11: Transformers Deep Dive
•
 Study (25h):
o
 Read "Attention Is All You Need" (3+ times)
o
 Watch: Andrej Karpathy, StatQuest, Yannic Kilcher
o
 Jay Alammar: Illustrated Transformer
o
 Understand: Self-attention, multi-head attention, positional encoding
•
 Project (20h): Attention mechanism from scratch
o
 NumPy implementation: Q, K, V matrices
o
 Scaled dot-product attention
o
 Multi-head intuition
o
 Detailed mathematical documentation
•
 LeetCode (5h): 3 Medium (maintenance mode)
Week 12: PyTorch & Buffer
•
 PyTorch (20h):
o
 Official tutorials: nn.Module, DataLoader
o
 Build: MNIST classifier
o
 Understand: Training loops, loss functions, optimizers
•
 Project (15h): Reimplement attention in PyTorch
•
 LeetCode (8h): 4 Medium (DP continued)
•
 Networking (5h): Share attention mechanism repo, ask for feedback
•
 Blog (10h): "Understanding Transformers: I Built Attention From Scratch"
o
 Mathematical explanations
o
 Code walkthrough
o
 Visual diagrams
Deliverables
•
 ✅ ML-from-scratch repo (Linear reg, Neural net, Attention)
•
 ✅ PyTorch fundamentals solid
•
 ✅ Can explain transformers intuitively
•
 ✅ 15 Medium problems (total: 70 problems)
•
 ✅ Blog post with technical depth
Success Metrics
•
 Can derive backpropagation on whiteboard
•
 Understand why attention works
•
 Comfortable with PyTorch basics
•
 Blog gets 100+ views
MONTH 4: LLM INFERENCE & PRODUCTION (PEAK 2)
Weeks 13-16 | Hours: 60-70/week | PEAK MONTH
Objective
Build production LLM inference system. Master containerization and deployment.
Skills Focus
•
 vLLM/SGLang for efficient serving
•
 Quantization (INT8, INT4, GPTQ, AWQ)
•
 FastAPI async patterns
•
 Docker & containerization
•
 Load testing with Locust
•
 Basic monitoring
Weekly Breakdown
Week 13: Docker & Containerization
•
 Learning (20h):
o
 Docker: Images, containers, Dockerfiles, volumes
o
 Multi-stage builds
o
 Docker Compose for multi-service apps
•
 Project (25h):
o
 Containerize Month 1 API
o
 Multi-container setup (API + database + Redis)
o
 Environment configuration
o
 Docker Compose for local dev
•
 LeetCode (10h): 5 Medium (DP, Heaps)
•
 Study vLLM: Read documentation, understand architecture
Week 14-15: LLM Inference API (2 weeks)
•
 Project (60h total over 2 weeks):
o
 Model Setup:
▪
 Choose: Llama 3.2 1B or 8B (quantized)
▪
 Set up vLLM locally
▪
 Test different quantization levels (INT8, INT4)
o
 API Development:
▪
 FastAPI with async endpoints
▪
 Token streaming (SSE)
▪
 Request validation (Pydantic)
▪
 Comprehensive error handling
▪
 Response caching (Redis)
o
 Deployment:
▪
 Containerize entire stack
▪
 Deploy to AWS/GCP free tier
▪
 Basic logging setup
o
 Testing:
▪
 Unit tests with pytest
▪
 Load testing with Locust (100+ concurrent users)
▪
 Measure: p50, p95, p99 latencies, throughput
•
 LeetCode (16h over 2 weeks): 8 Medium (Backtracking, Advanced DP)
•
 Networking: Share progress in vLLM Discord, ask questions
Week 16: Polish & Open Source
•
 Project (20h):
o
 Performance optimization based on load tests
o
 Documentation (README, API docs, benchmarks)
o
 Demo video (5 min): Show API, latency metrics
•
 Open Source (15h):
o
 Identify real issue in vLLM or Qdrant while building
o
 Study contribution guidelines
o
 Submit 1 PR (documentation or bug fix)
•
 LeetCode (8h): 4 Medium (review weak areas)
•
 Blog (10h): "Production LLM Inference: From vLLM to Deployment"
•
 Mock Interview: 2 sessions (1 coding, 1 system design intro)
Deliverables
•
 ✅ Live LLM API with public URL
•
 ✅ Load test results documented (graphs, metrics)
•
 ✅ 1 open source PR submitted to major project
•
 ✅ 17 Medium problems (total: 87 problems)
•
 ✅ Blog post with benchmarks
•
 ✅ Demo video published
Success Metrics
•
•
•
•
API handles 100+ concurrent users reliably
p95 latency documented
Understand vLLM internals
PR shows quality contribution mindset
MONTH 5: SYSTEM DESIGN & SUBFIFTY ARCHITECTURE
Weeks 17-20 | Hours: 55-65/week
Objective
Master system design. Design SubFifty architecture. Start building core components.
Skills Focus
•
 System design fundamentals (DDIA)
•
 Distributed systems concepts
•
 Vector databases (Qdrant)
•
 RAG architecture patterns
•
 Caching strategies
•
 GDPR compliance
Weekly Breakdown
Week 17: System Design Foundations
•
 Study (25h):
o
 DDIA Chapters 1-4 (Foundations, Data Models, Storage, Encoding)
o
 "Grokking the System Design Interview" (intro sections)
o
 Watch: System design interview videos
•
 Practice (15h):
o
 Design: Twitter feed, Instagram explore, URL shortener
o
 Focus: Drawing diagrams, explaining trade-offs
o
 Record yourself, review
•
 LeetCode (8h): 4 Medium (company-tagged)
•
 Networking (8h):
o
 Identify 20 engineers at target companies (LinkedIn)
o
 Follow their content
o
 Engage with 5 posts thoughtfully
Week 18: SubFifty Architecture Design
•
 Design Document (30h):
o
 Problem Statement: Why sub-50ms matters
o
 Architecture Diagram:
▪
 Components: API Gateway → Vector Search → LLM Server →
Cache → Monitoring
▪
 Data flow diagrams
o
 Tech Stack:
▪
 Backend: FastAPI (async)
▪
 Vector DB: Qdrant (HNSW indexing)
▪
 Cache: Redis (semantic caching)
▪
 LLM: vLLM (quantized Llama)
▪
 Monitoring: Prometheus + Grafana
▪
 Deployment: Docker + Kubernetes
o
 Database Schema: Tables, indexes, partitioning
o
 Latency Budget: Where milliseconds go
o
 GDPR Compliance: Data retention, deletion policies
•
 Study (15h):
o
 Qdrant documentation (HNSW algorithm)
o
 RAG patterns (LlamaIndex, LangChain architectures)
•
 LeetCode (8h): 4 Medium
Week 19: SubFifty - Start Building
•
 Project (30h):
o
 Basic RAG Setup:
▪
 FastAPI backend structure
▪
 Qdrant integration (local Docker)
▪
 Basic embedding generation (sentence-transformers)
▪
 Simple retrieval (cosine similarity)
▪
 LLM integration (OpenAI API or vLLM)
o
 Goal: End-to-end flow working (even if slow)
•
 Study (10h):
o
 DDIA Chapters 5-6 (Replication, Partitioning)
o
 Vector search papers
•
 LeetCode (8h): 4 Medium (Graphs, Trees review)
•
 Networking (5h): Share SubFifty design doc, ask for feedback
Week 20: System Design Practice & Buffer
•
 System Design (20h):
o
 Practice: YouTube recommendations, Uber matching, Search ranking
o
 ML-specific: Design recommendation system, design model serving
platform
o
 Focus: Communication, trade-offs, scaling
•
 SubFifty (15h):
o
 Continue building core features
o
 Add basic caching layer
•
 LeetCode (8h): 4 Medium
•
 Mock Interviews: 2 sessions (1 coding, 1 system design)
•
 Resume v1.0 (8h):
o
 FAANG-formatted
o
 Projects section prominent (SubFifty architecture, LLM API)
o
 ATS-optimized
o
 Get feedback from 2-3 people
Deliverables
•
 ✅ SubFifty architecture document (20-30 pages, professional)
•
 ✅ SubFifty basic RAG working end-to-end
•
 ✅ System design fundamentals solid
•
 ✅ 16 Medium problems (total: 103 problems)
•
 ✅ Resume v1.0 completed
•
 ✅ 10+ meaningful network connections
Success Metrics
•
 Can design ML systems confidently
•
 SubFifty architecture is compelling
•
 Resume scores 80%+ ATS
•
 Can explain RAG trade-offs clearly
MONTH 6: SUBFIFTY MVP & EARLY APPLICATIONS (PEAK 3)
Weeks 21-24 | Hours: 65-75/week | PEAK MONTH
Objective
Deploy SubFifty MVP to production. Start application wave. Get first users.
Skills Focus
•
 Kubernetes deployment
•
 Prometheus + Grafana monitoring
•
 Vector DB optimization (HNSW tuning)
•
 Semantic caching implementation
•
 Load testing at scale
•
 Production debugging
Weekly Breakdown
Week 21: Vector DB Optimization
•
 Project (35h):
o
 HNSW Tuning:
▪
 Parameter tuning (M, ef_construct, ef_search)
▪
 Test quantization (scalar vs product)
▪
 Distance metrics comparison
o
 Benchmarking:
▪
 Test at: 1K, 10K, 100K, 1M vectors
▪
 Measure: p50, p95, p99 latencies
▪
 Memory usage tracking
▪
 Document findings with graphs
•
 Study (10h): Kubernetes basics
•
 LeetCode (8h): 4 Medium (Greedy, Advanced Trees)
•
 Applications (10h): Research 30 companies, start tracking spreadsheet
Week 22: Semantic Caching & Deployment
•
 Project (40h):
o
 Semantic Cache:
▪
 Redis-based embedding cache
▪
 Similarity search on cached queries
▪
 Cache hit rate optimization
▪
 TTL strategies
o
 Cloud Deployment:
▪
 Choose: AWS (EKS) or GCP (GKE)
▪
 Kubernetes manifests (deployment, service, configmap)
▪
 Deploy: FastAPI + Qdrant + vLLM + Redis
▪
 Load balancing configuration
▪
 SSL/TLS + authentication
•
 LeetCode (8h): 4 Medium
•
 Networking (8h): DM 5 engineers who engaged with your content
Week 23: Monitoring & Load Testing
•
 Project (40h):
o
 Observability:
•
•
•
Week•
•
•
▪
 Prometheus metrics (latency, QPS, cache hit rate, errors)
▪
 Grafana dashboards (real-time visualization)
▪
 Alert rules (latency > 100ms, error rate > 1%)
▪
 Custom LLM metrics (tokens/sec, batch utilization)
o
 Load Testing:
▪
 Locust: Test 10, 100, 500, 1K, 5K concurrent users
▪
 Identify bottlenecks (profiling with cProfile, py-spy)
▪
 Optimize based on findings
▪
 Target: <50ms p95, <100ms p99
LeetCode (8h): 4 Medium/Hard
Applications (10h): Customize and send 15 applications
Mock Interview: 2 sessions
24: User Acquisition & Applications
Project (25h):
o
 Polish:
▪
 Excellent README (value prop, quick start, benchmarks)
▪
 Demo interface (simple UI)
▪
 Documentation (API docs, architecture wiki)
o
 Soft Launch:
▪
 Post in communities (vLLM, LangChain, r/LocalLLaMA)
▪
 "Looking for beta testers for SubFifty"
▪
 Onboarding guide + feedback form
▪
 Target: 5-10 beta users
Applications (20h):
o
 Send 20 more applications (total: 35 so far)
o
 Customize each (mention SubFifty, relate to their tech)
o
 Track in spreadsheet
LeetCode (8h): 4 Medium/Hard (total: 119 problems)
•
 Open Source (8h): Submit 2nd PR (substantial contribution)
•
 Blog (8h): "SubFifty: Achieving Sub-50ms RAG in Production"
Deliverables
•
 ✅ SubFifty MVP deployed to production with public URL
•
 ✅ Monitoring dashboard (Grafana) with 20+ metrics
•
 ✅ Load test results: <50ms p95, <100ms p99 documented
•
 ✅ 5-10 beta users actively testing
•
 ✅ 35 applications submitted (FAANG, AI leaders, infra companies)
•
 ✅ 2nd open source PR submitted
•
 ✅ 16 Medium/Hard problems (total: 119)
•
 ✅ Blog post with production insights
Success Metrics
•
 System handles 1K+ concurrent requests
•
 Real users providing feedback
•
 First phone screens scheduled
•
 SubFifty benchmarks are impressive
MONTH 7: LAUNCH, INTERVIEWS & OFFERS
Weeks 25-28 | Hours: 55-70/week (flexible for interviews)
Objective
Maximum visibility. Execute application blitz. Convert portfolio to offers.
Skills Focus
•
 Interview execution (coding + system design + behavioral)
•
 Technical communication
•
 Negotiation preparation
•
 Portfolio presentation
Weekly Breakdown
Week 25: Maximum Visibility Launch
•
 Content Creation (30h):
o
 Flagship Article (20h):
▪
 Title: "Building SubFifty: Achieving Sub-50ms RAG Response
Times"
▪
 2,500-3,000 words
▪
 Sections: Problem, Architecture, Optimizations, Benchmarks,
Lessons
▪
 Code snippets, diagrams, performance graphs
▪
 Publish: Dev.to, Medium, Hacker News, LinkedIn
o
 Demo Video (10h):
▪
 7-10 minutes, professional quality
▪
 Live system demo, latency metrics, architecture walkthrough
▪
 Upload to YouTube, embed everywhere
•
 GitHub Polish (10h):
o
 Perfect README, contributing guidelines, examples
o
 Clean code, remove TODOs, add comments
o
 Badges (build status, license, stars)
•
 Launch (8h):
o
 Monday: Reddit (r/LocalLLaMA, r/MachineLearning)
o
 Tuesday: Hacker News "Show HN: SubFifty"
o
 Wednesday: Twitter thread + LinkedIn
o
 Thursday-Friday: Discord communities, follow-up
•
 LeetCode (8h): 4 Medium/Hard (maintenance)
•
 Target: 100+ GitHub stars from launch
Week 26: Application Wave 2
•
 Applications (30h):
o
 Send 40 more applications (total: 75)
•
•
•
•
Week•
o
 Tier 1 - FAANG (15):
▪
 Google: Cloud AI, ML Engineer, Research Engineer (UK, Dublin,
Zurich)
▪
 Meta: ML Systems, AI Infrastructure (London)
▪
 Amazon: ML Engineer, Applied Scientist (UK, Dublin, Berlin)
▪
 Microsoft: AI Engineer, Azure ML (UK, Dublin)
▪
 Apple: ML Systems (UK if open)
o
 Tier 2 - AI Leaders (15):
▪
 OpenAI, Anthropic, Cohere, Hugging Face
▪
 Mistral AI, Stability AI (EU-based)
▪
 Adept, Inflection, Character.AI, Perplexity
o
 Tier 3 - Infrastructure (10):
▪
 Together AI, Modal, Replicate, Anyscale, Fireworks
▪
 Weights & Biases, LangChain, LlamaIndex
▪
 Qdrant, Pinecone, Weaviate
o
 Apply to BOTH SWE-ML and MLE roles at each company
Resume v2.0 (8h):
o
 Add SubFifty metrics (100+ stars, X users, <50ms p95)
o
 Add blog article with views
o
 Company-specific variants (emphasize different aspects)
LeetCode (10h): 5 Medium/Hard (company-tagged if possible)
Networking (10h): Ask 5-8 warm contacts for referrals
Mock Interview: 2 sessions
27: Interview Prep Intensive
System Design (20h):
o
 Practice 10 designs:
▪
 General: Twitter, Instagram, YouTube, Uber, WhatsApp
•
•
•
•
▪
 ML: Recommendation system, Model serving, Feature store, Real-
time prediction, Search ranking
o
 Record explanations, review, improve
Behavioral (12h):
o
 Prepare 10 STAR stories:
▪
 Tell me about yourself (60sec, 3min versions)
▪
 Most challenging project (SubFifty)
▪
 Failure + learning
▪
 Disagreement resolution
▪
 Tight deadline
▪
 Quick learning
▪
 Why this company (top 10 variants)
▪
 5-year vision
o
 SubFifty Pitch:
▪
 60 second elevator pitch
▪
 5 minute technical overview
▪
 15 minute deep dive
o
 Practice until natural
LeetCode (20h):
o
 10 Medium/Hard (company-tagged)
o
 Focus: Weak patterns, commonly asked
o
 Timed practice (45 min max)
o
 Review solutions thoroughly
Mock Interviews (8h): 3 sessions (coding + system design + behavioral)
Networking (8h):
o
 Reach out to 15 engineers at target companies
o
 Personalized messages referencing SubFifty
o
 Engage with their content
Week 28: Pipeline Management & Final Push
•
 Applications (15h):
o
 Send final 25 applications (total: 100)
o
 European companies (better sponsorship)
o
 Companies that starred SubFifty
o
 YC AI startups
o
 Referral applications
•
 Interview Management (20h):
o
 Respond to invitations within 24h
o
 Schedule strategically (space them out)
o
 Company-specific prep for each interview
o
 Thank-you emails after every interview
•
 SubFifty (15h):
o
 Fix bugs, add small features
o
 User support
o
 Target: 15-30 active users
o
 Collect testimonials
•
 LeetCode (10h): 5 problems (maintenance + review)
•
 Mock Interviews (8h): 3 more sessions (focus on weak areas)
•
 Content (5h):
o
 Update blog with user testimonials
o
 Share "SubFifty: 1 Month Post-Launch" update
Deliverables - Month 7 Complete
•
 ✅ SubFifty: 100+ stars, 15-30 users, production-grade
•
 ✅ Flagship article published (goal: 1K+ views)
•
 ✅ Demo video (professional quality)
•
 ✅ 100 applications submitted to both SWE-ML and MLE roles
•
 ✅ 10+ mock interviews completed
•
 ✅ 19 Medium/Hard problems (total: 138)
•
 ✅ Active interview pipeline (5-15 phone screens)
•
 ✅ 2 open source contributions merged
•
 ✅ 20-30 warm network connections
Success Metrics
•
 Multiple interview processes active
•
 2-5 final round interviews scheduled or completed
•
 1-3 offers received or imminent
•
 SubFifty recognized in LLM community
POST-MONTH 7: THE CLOSE
Weeks 29-32 (as needed)
Activities
•
 Continue interviews: Some processes take 6-8 weeks total
•
 SubFifty maintenance: Keep system running, fix bugs, support users
•
 LeetCode: 1-2 problems/day (maintenance mode)
•
 Networking: Leverage success stories, help others
•
 Content: Write follow-up based on learnings
Expected Timeline by Week 32
•
 100 applications submitted
•
 15-25 initial screens completed
•
 8-12 technical phone screens
•
 3-6 onsite/final rounds
•
 2-5 offers received
Offer Conversion Math
Why 2-5 offers is realistic for dual-track applications:
•
•
•
•
•
100 applications (50 SWE-ML, 50 MLE)
Initial response: 15-25% (15-25 screens) - higher because of strong portfolio
Phone screen → onsite: 40-50% (6-12 onsites)
Onsite → offer: 30-50% (2-6 offers)
Expected range: 2-5 offers (with SubFifty + dual-track strategy)
THE FINAL SCORECARD
Technical Mastery
•
 LeetCode: 138 problems (deeply understood, can teach to others)
o
 17 Easy, 121 Medium/Hard
o
 Patterns mastered: Arrays, Strings, Trees, Graphs, DP, Stacks, Heaps,
Backtracking
•
 Projects: 8 deployed (3 learning projects, API, LLM inference, SubFifty, 2 ML
repos)
•
 Open Source: 2 merged PRs to major projects (vLLM, Qdrant, or similar)
•
 System Design: Can design general and ML-specific systems confidently
Portfolio Impact
•
 SubFifty: Production RAG system
o
 100+ GitHub stars
o
 15-30 active users
o
 <50ms p95 latency (documented)
o
 Comprehensive monitoring
o
 GDPR-compliant
•
 Blog: 5-6 technical articles (combined 2K+ views)
•
 Demo Video: Professional SubFifty walkthrough
•
 GitHub: 200+ day commit streak, professional presence
Network & Visibility
•
 Connections: 20-30 warm relationships at target companies
•
 Referrals: 10-15 obtained
•
 Community: Known in r/LocalLLaMA, vLLM Discord, LangChain community
•
 Recognition: SubFifty featured on HN, Reddit, mentioned in newsletters
Applications & Interviews
•
 Applications: 100 (50 SWE-ML, 50 MLE)
•
 Phone Screens: 15-25
•
 Onsites: 6-12
•
 Offers: 2-5 expected
•
 Target: EU/UK sponsorship from FAANG or Tier-1 AI company
CRITICAL SUCCESS FACTORS
What Makes This Work
1. Dual-track applications (SWE-ML + MLE doubles your chances)
2. SubFifty is genuinely impressive (solves real problem, production-grade)
3. CS background accelerates learning (not starting from zero)
4. Realistic LeetCode targets (138 deeply understood > 200 rushed)
5. Build in public (visibility through communities, networking)
6. Open source contributions (shows you can work with production codebases)
7. Strategic timing (applications start Month 6, not Month 7)
What Will Kill This
1. Tutorial hell - Watching videos instead of building
2. Perfect code syndrome - Never shipping because it's not "ready"
3. LeetCode grinding without understanding - 200 problems at 50% depth
4. Isolation - Building SubFifty alone without feedback
5. Application spray-and-pray - Generic applications with no customization
6. Giving up at Week 15 - When it gets hard and you're behind schedule
THE RESOURCE ARSENAL
Python & Fundamentals
•
 Learning: Corey Schafer YouTube, "Python for Everybody"
•
 Practice: Real Python, Official Python Tutorial
•
 APIs: FastAPI official docs
Data Structures & Algorithms
•
 Foundation: freeCodeCamp DSA Course (YouTube, 15 hours)
•
 Patterns: NeetCode 150 (website + YouTube explanations)
•
 Practice: LeetCode (Premium for company-tagged problems)
•
 Mocks: Pramp (free), Interviewing.io (paid)
Machine Learning & Deep Learning
•
 Math: 3Blue1Brown (Linear Algebra + Neural Networks), Khan Academy
•
 ML: Andrew Ng Machine Learning Specialization (Coursera)
•
 DL: Andrew Ng Deep Learning Specialization (Coursera)
•
 Visual: Jay Alammar blog (Illustrated Transformer, BERT, GPT)
•
 Papers: "Attention Is All You Need" (arXiv)
•
 Framework: PyTorch official tutorials
System Design
•
 Book: "Designing Data-Intensive Applications" by Martin Kleppmann
•
 Course: "Grokking the System Design Interview" (Educative.io)
•
 ML Design: Chip Huyen's ML Systems Design guide
•
 Videos: System Design Interview channel (YouTube)
Production & Infrastructure
•
 Docker: Official Docker docs + YouTube tutorials
•
 Kubernetes: Official K8s docs, "Kubernetes Up & Running" book
•
 FastAPI: Official documentation (excellent)
•
 vLLM: vLLM GitHub repo + docs
•
 Qdrant: Qdrant documentation + tutorials
•
 Monitoring: Prometheus docs, Grafana tutorials
•
 Load Testing: Locust documentation
Strategic Intelligence
•
 Trends: Marina Wyss YouTube (LLM infrastructure updates)
•
 Communities: r/LocalLLaMA, r/MachineLearning, vLLM Discord, LangChain
Discord
•
 News: Hacker News, Papers with Code
•
 Salaries: Levels.fyi, Blind
WEEK-BY-WEEK LEETCODE BREAKDOWN
Month 1 (Weeks 1-4): 17 Easy
•
 Week 1: 4 Easy (Arrays)
•
 Week 2: 4 Easy (Strings, Hash Tables)
•
 Week 3: 4 Easy (Two Pointers)
•
 Week 4: 5 Easy (Review, solidify)
Month 2 (Weeks 5-8): 38 Medium
•
 Week 5: 10 Medium (Trees)
•
 Week 6: 13 Medium (8 Trees, 5 Graphs)
•
 Week 7: 10 Medium (Stacks, Queues, Binary Search)
•
 Week 8: 8 Medium (Review + new)
Month 3 (Weeks 9-12): 15 Medium
•
 Week 9: 4 Medium (Linked Lists)
•
 Week 10: 4 Medium (Stacks, DP intro)
•
 Week 11: 3 Medium (maintenance)
•
 Week 12: 4 Medium (DP continued)
Month 4 (Weeks 13-16): 17 Medium
•
 Week 13: 5 Medium (DP, Heaps)
•
 Week 14-15: 8 Medium (Backtracking, Advanced DP)
•
 Week 16: 4 Medium (review)
Month 5 (Weeks 17-20): 16 Medium
•
 Week 17-20: 4 Medium/week (company-tagged, maintenance)
Month 6 (Weeks 21-24): 16 Medium/Hard
•
 Week 21-24: 4 Medium/Hard per week (focus shifting to interviews)
Month 7 (Weeks 25-28): 19 Medium/Hard
•
 Week 25: 4 (maintenance)
•
 Week 26: 5 (company-tagged)
•
 Week 27: 10 (intensive prep)
•
 Week 28: 5 (review)
Total: 138 problems (17 Easy, 121 Medium/Hard)
MONTHLY TIME ALLOCATION SUMMARY
Month 1 (55-65h/week)
•
 Python/Projects: 35-40h
•
 LeetCode: 8-10h
•
 Learning: 10-15h
•
 Writing/Admin: 2-5h
Month 2 - PEAK (60-70h/week)
•
 DSA Practice: 30-35h
•
 Learning: 15-20h
•
 Projects: 10-12h
•
 Mocks/Writing: 5-8h
Month 3 (55-65h/week)
•
 ML Learning: 25-30h
•
 Projects: 20-25h
•
 LeetCode: 8-10h
•
 Writing: 5-8h
Month 4 - PEAK (60-70h/week)
•
 LLM API Project: 50-60h
•
 LeetCode: 10-12h
•
 Open Source: 8-15h
•
 Mocks/Writing: 5-10h
Month 5 (55-65h/week)
•
 System Design: 20-25h
•
 SubFifty Design/Build: 25-30h
•
 LeetCode: 8-10h
•
 Networking/Resume: 8-12h
Month 6 - PEAK (65-75h/week)
•
 SubFifty Development: 40-45h
•
 Applications: 10-15h
•
 LeetCode: 8-10h
•
 Open Source/Mocks: 8-12h
Month 7 (55-70h/week, flexible)
•
 Content/Launch: 20-25h (Week 25)
•
 Applications: 20-30h (Weeks 26-28)
•
 Interview Prep: 25-30h (Week 27)
•
 Interviews: 10-20h (active pipeline)
•
 SubFifty/LeetCode: 10-15h
